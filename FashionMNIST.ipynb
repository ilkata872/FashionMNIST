{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "nmb2incjYhRs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2PFFFgAwcH-",
        "outputId": "d8711c50-6abf-4458-af35-cc7717a087c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c84401661f0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAzazxN8ZYHb",
        "outputId": "44f7441a-ffb6-4ca5-afad-fa0f318468f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()]) #*** IMPORTANT THE [] REMEBER THIS!!!!!"
      ],
      "metadata": {
        "id": "hzeTAXKGa67U"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Data**"
      ],
      "metadata": {
        "id": "K_HlNMMq1ZQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = datasets.FashionMNIST(root='/data', train=True, transform = transform, download = True)\n",
        "test_data = datasets.FashionMNIST(root='/data', train=False, transform = transform, download = True)"
      ],
      "metadata": {
        "id": "zGlcXUxsZr5O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spliting the data into train, test batches of 64 images per batch"
      ],
      "metadata": {
        "id": "LirpbiRr1hde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_split = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "test_split = DataLoader(test_data, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "02AZp9Wzct33"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing our Neural Network using convolutional layers, batch norm, Pooling, Flattening and fully connected Linear layers as well as ReLU activation function."
      ],
      "metadata": {
        "id": "cJBRx1qp1rhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.Flatten = nn.Flatten()\n",
        "\n",
        "\n",
        "    self.fc1 = nn.Linear(7*7*64, 256)\n",
        "    self.drop1 = nn.Dropout(0.5)\n",
        "\n",
        "    self.fc2 = nn.Linear(256, 128)\n",
        "    self.drop2 = nn.Dropout(0.5)\n",
        "\n",
        "    self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "    x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "    x = self.Flatten(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.drop1(x)\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.drop2(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "cnoWuwcVdPJt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sending the model to GPU(cuda) if availabe for faster computing"
      ],
      "metadata": {
        "id": "egm0lPu02AYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "jIPT6wu7jIzl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the loss function as well as the optimizer for out model"
      ],
      "metadata": {
        "id": "8RTRQp0p2KoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "vbQfU10ajSEj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making train reusable function as well as a test one that returns loss and accuracy"
      ],
      "metadata": {
        "id": "LCptcPq42QeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, data_loader, loss_fn, optimizer, device):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  for X, y in data_loader:\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "    predicted = y_pred.argmax(dim=1)\n",
        "    correct += (predicted == y).sum().item()\n",
        "  avg_loss = total_loss / len(data_loader)\n",
        "  avg_acc = correct / len(data_loader.dataset)\n",
        "\n",
        "  return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "7WmDD7iejka7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model, data_loader, loss_fn, device):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  preds = []\n",
        "  true = []\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      y_pred = model(X)\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      total_loss += loss.item()\n",
        "      predicted = y_pred.argmax(dim=1)\n",
        "      correct += (predicted == y).sum().item()\n",
        "      preds.extend(predicted.cpu().numpy())\n",
        "      true.extend(y.cpu().numpy())\n",
        "\n",
        "  avg_loss = total_loss / len(data_loader)\n",
        "  avg_acc = correct / len(data_loader.dataset)\n",
        "  report = classification_report(true, preds)\n",
        "  return avg_loss, avg_acc, report\n"
      ],
      "metadata": {
        "id": "TYvHO0IckXDv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The actual train/validation loop mad for max 50 epochs but It has an early stopping to prevent the model from Overfitting"
      ],
      "metadata": {
        "id": "hSNkgwU72ZTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 50\n",
        "patience = 3\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc = train_step(model, train_split, loss_fn, optimizer, device)\n",
        "  test_loss, test_acc, test_report = test_step(model, test_split, loss_fn, device)\n",
        "  print(f\"epoch: {epoch +1 }\")\n",
        "  print(f\"train loss: {train_loss} | train accuracy ={train_acc}\")\n",
        "  print(f\"test loss: {test_loss} | test_acc = {test_acc}\")\n",
        "  print(f\"test report: {test_report}\")\n",
        "\n",
        "  if test_loss < best_val_loss:\n",
        "    best_val_loss = test_loss\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "  else:\n",
        "    epochs_no_improve += 1\n",
        "    print(\"No improvement to the loss\")\n",
        "    if epochs_no_improve == patience:\n",
        "      print(\"Early stopping activated the model started overfitting!\")\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDEna4b7nBGI",
        "outputId": "d37319e9-944b-473f-e2eb-0f868bd2be03"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\n",
            "train loss: 0.5667919671294023 | train accuracy =0.7969833333333334\n",
            "test loss: 0.34356019793042714 | test_acc = 0.8754\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.80      0.82      1000\n",
            "           1       1.00      0.96      0.98      1000\n",
            "           2       0.86      0.75      0.80      1000\n",
            "           3       0.80      0.95      0.87      1000\n",
            "           4       0.78      0.77      0.77      1000\n",
            "           5       0.98      0.97      0.98      1000\n",
            "           6       0.64      0.69      0.66      1000\n",
            "           7       0.94      0.96      0.95      1000\n",
            "           8       0.99      0.95      0.97      1000\n",
            "           9       0.96      0.95      0.96      1000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "epoch: 2\n",
            "train loss: 0.37337280330119105 | train accuracy =0.8705333333333334\n",
            "test loss: 0.30037531332605205 | test_acc = 0.8895\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.82      0.84      1000\n",
            "           1       0.99      0.98      0.98      1000\n",
            "           2       0.76      0.90      0.83      1000\n",
            "           3       0.85      0.93      0.89      1000\n",
            "           4       0.83      0.78      0.80      1000\n",
            "           5       0.99      0.93      0.96      1000\n",
            "           6       0.77      0.63      0.69      1000\n",
            "           7       0.91      0.98      0.95      1000\n",
            "           8       0.97      0.99      0.98      1000\n",
            "           9       0.96      0.95      0.96      1000\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "epoch: 3\n",
            "train loss: 0.31822558397899814 | train accuracy =0.8897\n",
            "test loss: 0.2767089830747076 | test_acc = 0.8983\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.77      0.90      0.83      1000\n",
            "           3       0.88      0.94      0.91      1000\n",
            "           4       0.88      0.74      0.81      1000\n",
            "           5       0.99      0.97      0.98      1000\n",
            "           6       0.78      0.63      0.70      1000\n",
            "           7       0.95      0.96      0.96      1000\n",
            "           8       0.98      0.98      0.98      1000\n",
            "           9       0.96      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n",
            "epoch: 4\n",
            "train loss: 0.2870285242938919 | train accuracy =0.9003833333333333\n",
            "test loss: 0.26111834292199204 | test_acc = 0.9045\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.77      0.83      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.88      0.83      0.85      1000\n",
            "           3       0.90      0.90      0.90      1000\n",
            "           4       0.80      0.91      0.85      1000\n",
            "           5       0.99      0.98      0.98      1000\n",
            "           6       0.71      0.74      0.73      1000\n",
            "           7       0.96      0.97      0.96      1000\n",
            "           8       0.96      0.99      0.97      1000\n",
            "           9       0.97      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.91      0.90      0.90     10000\n",
            "weighted avg       0.91      0.90      0.90     10000\n",
            "\n",
            "epoch: 5\n",
            "train loss: 0.2644632234931119 | train accuracy =0.9077333333333333\n",
            "test loss: 0.240322108054237 | test_acc = 0.9154\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87      1000\n",
            "           1       0.98      0.99      0.98      1000\n",
            "           2       0.89      0.85      0.87      1000\n",
            "           3       0.91      0.92      0.92      1000\n",
            "           4       0.87      0.87      0.87      1000\n",
            "           5       0.99      0.97      0.98      1000\n",
            "           6       0.74      0.76      0.75      1000\n",
            "           7       0.95      0.96      0.96      1000\n",
            "           8       0.98      0.99      0.99      1000\n",
            "           9       0.97      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "epoch: 6\n",
            "train loss: 0.2479671262649458 | train accuracy =0.9132333333333333\n",
            "test loss: 0.2657323503380368 | test_acc = 0.9029\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.93      0.85      1000\n",
            "           1       0.99      0.99      0.99      1000\n",
            "           2       0.77      0.92      0.84      1000\n",
            "           3       0.89      0.94      0.91      1000\n",
            "           4       0.89      0.76      0.82      1000\n",
            "           5       0.99      0.97      0.98      1000\n",
            "           6       0.85      0.59      0.69      1000\n",
            "           7       0.95      0.98      0.96      1000\n",
            "           8       0.97      0.99      0.98      1000\n",
            "           9       0.98      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.91      0.90      0.90     10000\n",
            "weighted avg       0.91      0.90      0.90     10000\n",
            "\n",
            "No improvement to the loss\n",
            "epoch: 7\n",
            "train loss: 0.2337895854830996 | train accuracy =0.9169\n",
            "test loss: 0.23910023803543892 | test_acc = 0.912\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.82      0.90      0.86      1000\n",
            "           3       0.87      0.96      0.91      1000\n",
            "           4       0.87      0.84      0.85      1000\n",
            "           5       0.99      0.98      0.98      1000\n",
            "           6       0.80      0.67      0.73      1000\n",
            "           7       0.96      0.95      0.96      1000\n",
            "           8       0.99      0.99      0.99      1000\n",
            "           9       0.95      0.98      0.97      1000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "epoch: 8\n",
            "train loss: 0.22341007358436263 | train accuracy =0.9220666666666667\n",
            "test loss: 0.23281614465793227 | test_acc = 0.9172\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88      1000\n",
            "           1       1.00      0.97      0.99      1000\n",
            "           2       0.86      0.89      0.87      1000\n",
            "           3       0.90      0.93      0.91      1000\n",
            "           4       0.87      0.87      0.87      1000\n",
            "           5       0.99      0.97      0.98      1000\n",
            "           6       0.78      0.72      0.75      1000\n",
            "           7       0.96      0.97      0.97      1000\n",
            "           8       0.98      0.98      0.98      1000\n",
            "           9       0.96      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "epoch: 9\n",
            "train loss: 0.21229308914702966 | train accuracy =0.92575\n",
            "test loss: 0.23991647362709045 | test_acc = 0.9146\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.86      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.83      0.92      0.87      1000\n",
            "           3       0.91      0.93      0.92      1000\n",
            "           4       0.86      0.88      0.87      1000\n",
            "           5       0.98      0.99      0.99      1000\n",
            "           6       0.85      0.61      0.71      1000\n",
            "           7       0.98      0.95      0.96      1000\n",
            "           8       0.97      0.99      0.98      1000\n",
            "           9       0.96      0.98      0.97      1000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "No improvement to the loss\n",
            "epoch: 10\n",
            "train loss: 0.19909322062439755 | train accuracy =0.9294333333333333\n",
            "test loss: 0.23592757492972788 | test_acc = 0.9165\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87      1000\n",
            "           1       0.99      0.99      0.99      1000\n",
            "           2       0.85      0.90      0.87      1000\n",
            "           3       0.92      0.91      0.92      1000\n",
            "           4       0.85      0.90      0.87      1000\n",
            "           5       0.99      0.98      0.98      1000\n",
            "           6       0.80      0.66      0.72      1000\n",
            "           7       0.95      0.98      0.97      1000\n",
            "           8       0.99      0.98      0.99      1000\n",
            "           9       0.98      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "No improvement to the loss\n",
            "epoch: 11\n",
            "train loss: 0.19209717497674386 | train accuracy =0.9319166666666666\n",
            "test loss: 0.23186951268250774 | test_acc = 0.9172\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.91      0.87      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.89      0.86      0.87      1000\n",
            "           3       0.93      0.91      0.92      1000\n",
            "           4       0.83      0.92      0.87      1000\n",
            "           5       0.99      0.99      0.99      1000\n",
            "           6       0.81      0.67      0.73      1000\n",
            "           7       0.94      0.99      0.97      1000\n",
            "           8       0.98      0.99      0.98      1000\n",
            "           9       0.99      0.95      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "epoch: 12\n",
            "train loss: 0.18752657243811183 | train accuracy =0.9332666666666667\n",
            "test loss: 0.2505960752060459 | test_acc = 0.914\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87      1000\n",
            "           1       0.99      0.99      0.99      1000\n",
            "           2       0.90      0.83      0.87      1000\n",
            "           3       0.91      0.92      0.92      1000\n",
            "           4       0.78      0.94      0.86      1000\n",
            "           5       0.99      0.97      0.98      1000\n",
            "           6       0.81      0.68      0.74      1000\n",
            "           7       0.94      0.99      0.97      1000\n",
            "           8       0.97      0.99      0.98      1000\n",
            "           9       0.98      0.96      0.97      1000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n",
            "No improvement to the loss\n",
            "epoch: 13\n",
            "train loss: 0.1782206069670125 | train accuracy =0.93645\n",
            "test loss: 0.2306585645979377 | test_acc = 0.917\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.87      0.86      1000\n",
            "           1       0.99      0.99      0.99      1000\n",
            "           2       0.91      0.83      0.87      1000\n",
            "           3       0.93      0.92      0.92      1000\n",
            "           4       0.83      0.92      0.87      1000\n",
            "           5       0.98      0.99      0.99      1000\n",
            "           6       0.75      0.73      0.74      1000\n",
            "           7       0.96      0.98      0.97      1000\n",
            "           8       0.99      0.98      0.99      1000\n",
            "           9       0.98      0.96      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "epoch: 14\n",
            "train loss: 0.1713293930297213 | train accuracy =0.9384833333333333\n",
            "test loss: 0.23678006908031785 | test_acc = 0.9242\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.88      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.89      0.88      0.88      1000\n",
            "           3       0.93      0.92      0.92      1000\n",
            "           4       0.89      0.88      0.89      1000\n",
            "           5       0.99      0.99      0.99      1000\n",
            "           6       0.77      0.79      0.78      1000\n",
            "           7       0.95      0.99      0.97      1000\n",
            "           8       0.99      0.98      0.98      1000\n",
            "           9       0.99      0.95      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "No improvement to the loss\n",
            "epoch: 15\n",
            "train loss: 0.1632743726438805 | train accuracy =0.94125\n",
            "test loss: 0.2615281599010252 | test_acc = 0.9138\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.87      1000\n",
            "           1       0.99      0.99      0.99      1000\n",
            "           2       0.94      0.79      0.86      1000\n",
            "           3       0.92      0.92      0.92      1000\n",
            "           4       0.80      0.94      0.86      1000\n",
            "           5       0.99      0.97      0.98      1000\n",
            "           6       0.76      0.76      0.76      1000\n",
            "           7       0.92      0.99      0.96      1000\n",
            "           8       0.98      0.99      0.98      1000\n",
            "           9       0.99      0.94      0.96      1000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.92      0.91      0.91     10000\n",
            "weighted avg       0.92      0.91      0.91     10000\n",
            "\n",
            "No improvement to the loss\n",
            "epoch: 16\n",
            "train loss: 0.1619419575706601 | train accuracy =0.9425833333333333\n",
            "test loss: 0.24632118077604634 | test_acc = 0.9166\n",
            "test report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.86      1000\n",
            "           1       0.99      0.99      0.99      1000\n",
            "           2       0.90      0.84      0.87      1000\n",
            "           3       0.92      0.91      0.91      1000\n",
            "           4       0.81      0.93      0.87      1000\n",
            "           5       0.99      0.99      0.99      1000\n",
            "           6       0.79      0.72      0.75      1000\n",
            "           7       0.96      0.97      0.97      1000\n",
            "           8       0.98      0.98      0.98      1000\n",
            "           9       0.97      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "No improvement to the loss\n",
            "Early stopping activated the model started overfitting!\n"
          ]
        }
      ]
    }
  ]
}